import os
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from pathlib import Path

# è®¾ç½®å­—ä½“å’Œæ ·å¼ï¼Œæ–¹ä¾¿ç›´æ¥æ”¾å…¥è®ºæ–‡ (Paper-ready plots)
plt.rcParams.update({'font.size': 12, 'font.family': 'sans-serif'})
sns.set_theme(style="whitegrid")

# SensatUrban 13 Classes
CLASS_NAMES = [
    "Ground", "Vegetation", "Building", "Wall", "Bridge", "Parking", 
    "Rail", "TrafficRoad", "StreetFurniture", "Car", "Footpath", "Bike", "Water"
]

import os
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from pathlib import Path

# ... ä¿æŒ CLASS_NAMES ä¸å˜ ...

# ğŸ‘‡ [ä¿®æ”¹ç‚¹ 1] è®¾å®šä½ çš„ train æ–‡ä»¶å¤¹çš„æ ¹ç›®å½•
# æ³¨æ„ï¼šå¦‚æœä½ ä¹‹å‰ç”¨ç»å¯¹è·¯å¾„æ²¡é—®é¢˜ï¼Œå¼ºçƒˆå»ºè®®æ”¹æˆç»å¯¹è·¯å¾„ï¼Œä¾‹å¦‚ "/data/datasets/OpenDataLab___SensatUrban/data/processed_10d/train"
TRAIN_DIR = Path("../Pointcept/data/OpenDataLab___SensatUrban/data/processed_10d/train")

# ğŸ‘‡ [ä¿®æ”¹ç‚¹ 2] è‡ªåŠ¨è·å–è¯¥ç›®å½•ä¸‹æ‰€æœ‰çš„å­æ–‡ä»¶å¤¹è·¯å¾„
# p.is_dir() ç¡®ä¿æˆ‘ä»¬åªæ‹¿æ–‡ä»¶å¤¹ï¼Œä¸æ‹¿ train.txt è¿™ç§æ–‡ä»¶
SAMPLE_CHUNKS = [str(p) for p in TRAIN_DIR.iterdir() if p.is_dir()]
# ğŸ‘‡ [ä¿®æ”¹ç‚¹ 1] åœ¨è·å–æ‰€æœ‰çš„ block åï¼Œéšæœºæ‰“ä¹±å¹¶åªå–å‰ 100 ä¸ªï¼
import random

SAMPLE_CHUNKS = [str(p) for p in TRAIN_DIR.iterdir() if p.is_dir()]
random.seed(42)
random.shuffle(SAMPLE_CHUNKS)
SAMPLE_CHUNKS = SAMPLE_CHUNKS[:100]  # ğŸ‘ˆ é™åˆ¶ä¸º 100 ä¸ª Blockï¼Œé˜²æ­¢å†…å­˜çˆ†ç‚¸ï¼

print(f"ğŸ”¥ è‡ªåŠ¨æ‰¾åˆ°äº† {len(SAMPLE_CHUNKS)} ä¸ª Block å°†è¿›è¡ŒæŠ½æ ·åˆ†æï¼")

def load_and_compute_features(chunk_paths, max_points_per_chunk=20000): # ç¨å¾®è°ƒå°ä¸€ç‚¹ï¼Œ2ä¸‡å®Œå…¨å¤Ÿäº†
    all_dfs = []
    
    for path in chunk_paths:
        p = Path(path)
        if not p.exists():
            continue
            
        print(f"Loading data from {p.name}...")
        segment = np.load(p / "segment.npy").reshape(-1)
        extra_feat = np.load(p / "extra_feat.npy") 
        
        # å¼ºåˆ¶ç‰¹å¾å€¼é™åºæ’åˆ—
        eigenvalues = np.sort(extra_feat[:, :3], axis=1)[:, ::-1]
        l1, l2, l3 = eigenvalues[:, 0], eigenvalues[:, 1], eigenvalues[:, 2]
        density = extra_feat[:, 3]
        
        eps = 1e-8
        l1_safe = l1 + eps
        linearity = (l1 - l2) / l1_safe
        planarity = (l2 - l3) / l1_safe
        scattering = l3 / l1_safe
        
        df = pd.DataFrame({
            "Class_ID": segment,
            "Lambda_1": l1,
            "Lambda_2": l2,
            "Lambda_3": l3,
            "Density": density,
            "Linearity": linearity,
            "Planarity": planarity,
            "Scattering": scattering
        })
        
        # è¿‡æ»¤æ‰ ignore_index
        df = df[df["Class_ID"] < len(CLASS_NAMES)]
        df["Class_Name"] = df["Class_ID"].apply(lambda x: CLASS_NAMES[x])
        
        # ğŸš¨ [ä¿®å¤ç‚¹ 2] ä¿®å¤é‡‡æ · Bugï¼šåŠ å…¥ min() ä¿æŠ¤ï¼
        if len(df) > max_points_per_chunk:
            is_rare = df["Class_Name"].isin(["Bike", "StreetFurniture", "Car"])
            df_rare = df[is_rare]
            df_common = df[~is_rare]
            
            # ç¡®ä¿è¦é‡‡æ ·çš„æ•°é‡ä¸ä¼šè¶…è¿‡ common ç‚¹çš„æ€»æ•°
            sample_size = min(len(df_common), max_points_per_chunk)
            
            df_common_sampled = df_common.sample(n=sample_size, random_state=42)
            df = pd.concat([df_rare, df_common_sampled])
            
        all_dfs.append(df)
        
    if not all_dfs:
        raise ValueError("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ•°æ®ï¼")
        
    return pd.concat(all_dfs, ignore_index=True)

def plot_feature_distributions(df, feature_name, save_dir="./analysis_output"):
    os.makedirs(save_dir, exist_ok=True)
    
    plt.figure(figsize=(14, 6))
    
    # æˆ‘ä»¬æŠŠ Bike å•ç‹¬æ ‡çº¢ï¼Œå…¶ä»–é¢œè‰²è°ƒæ·¡ï¼Œä»¥çªå‡ºå¯¹æ¯”
    palette = {name: "red" if name == "Bike" else "lightgray" for name in CLASS_NAMES}
    
    # é‡‡ç”¨ Violin Plot å±•ç¤ºåˆ†å¸ƒè§„å¾‹
    sns.violinplot(
        data=df, 
        x="Class_Name", 
        y=feature_name, 
        palette=palette,
        scale="width",
        inner="quartile" # æ˜¾ç¤ºå››åˆ†ä½æ•°
    )
    
    plt.xticks(rotation=45, ha="right")
    plt.title(f"Distribution of {feature_name} across SensatUrban Classes", fontweight='bold')
    plt.ylabel(feature_name)
    plt.xlabel("")
    plt.tight_layout()
    
    # æˆªæ–­æå€¼ (Outliers) ä»¥è·å¾—æ›´å¥½çš„å¯è§†åŒ–æ•ˆæœ
    lower = df[feature_name].quantile(0.01)
    upper = df[feature_name].quantile(0.99)
    plt.ylim(lower, upper)
    
    save_path = os.path.join(save_dir, f"{feature_name}_distribution.png")
    plt.savefig(save_path, dpi=300)
    print(f"Saved plot: {save_path}")
    plt.close()

if __name__ == "__main__":
    # 1. æŠ½å–æ•°æ®
    df_combined = load_and_compute_features(SAMPLE_CHUNKS)
    print(f"Total points analyzed: {len(df_combined)}")
    
    # 2. å¦‚æœç‚¹æ•°å¤ªå¤šå¯¼è‡´ç”»å›¾ææ…¢ï¼Œå¯ä»¥éšæœºé™é‡‡æ · (Random Subsampling)
    if len(df_combined) > 500000:
        print("Downsampling data for faster plotting...")
        df_combined = df_combined.sample(n=500000, random_state=42)
        
    # 3. ç»˜åˆ¶æˆ‘ä»¬å…³å¿ƒçš„æ‰€æœ‰ç‰¹å¾
    features_to_plot = ["Linearity", "Planarity", "Scattering", "Density", "Lambda_1"]
    
    for feat in features_to_plot:
        plot_feature_distributions(df_combined, feat)
        
    # 4. æ‰“å°å‡å€¼ç»Ÿè®¡è¡¨ (é’ˆå¯¹ Bike çš„ç‰¹æ®Šåˆ†æ)
    print("\n=== Mean Values per Class ===")
    mean_stats = df_combined.groupby("Class_Name")[features_to_plot].mean()
    print(mean_stats)
    
    # é‡ç‚¹æŸ¥çœ‹ Bike å’Œæ˜“æ··æ·†ç±»åˆ« (Car, StreetFurniture) çš„å·®å¼‚
    print("\nğŸ” é‡ç‚¹å·®å¼‚å¯¹æ¯” (Bike vs StreetFurniture vs Car):")
    focus_classes = ["Bike", "StreetFurniture", "Car", "Vegetation"]
    focus_stats = mean_stats.loc[focus_classes]
    print(focus_stats)