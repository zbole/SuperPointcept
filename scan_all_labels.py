import torch
import numpy as np
import os
from pointcept.datasets.semantic_kitti import SemanticKITTIDataset
from tqdm import tqdm
import multiprocessing

def scan_worker(args):
    """å•ä¸ªæ ·æœ¬çš„æ‰«æå‡½æ•°ï¼Œç”¨äºå¤šè¿›ç¨‹"""
    dataset, idx = args
    try:
        data = dataset[idx]
        segment = data['segment']
        
        if isinstance(segment, torch.Tensor):
            unique_vals = torch.unique(segment).numpy()
        else:
            unique_vals = np.unique(segment)
            
        # æ£€æŸ¥æ˜¯å¦åªæœ‰ -1 åˆ° 18
        # å¦‚æœå‡ºç° > 18 çš„æ•°ï¼Œæˆ–è€… < -1 çš„æ•°ï¼Œå°±æ˜¯éæ³•çš„
        invalid_mask = (unique_vals > 18) | (unique_vals < -1)
        
        if np.any(invalid_mask):
            return idx, unique_vals[invalid_mask]
        return None
    except Exception as e:
        return idx, f"Error: {str(e)}"

def check_all_data():
    print(">>> æ­£åœ¨åˆå§‹åŒ–æ•°æ®é›†ç´¢å¼•...")
    
    data_root = 'data/semantic_kitti'
    
    # ç®€å•çš„é…ç½®ï¼Œåªä¸ºäº†è¯»æ ‡ç­¾
    transform_list = [
        dict(type="GridSample", grid_size=0.05, hash_type="fnv", mode="train", return_grid_coord=True),
        dict(type="ToTensor"),
        dict(type="Collect", keys=("coord", "grid_coord", "segment"), feat_keys=("coord", "strength"))
    ]
    
    dataset = SemanticKITTIDataset(
        split='train',
        data_root=data_root,
        transform=transform_list, 
        test_mode=False,
        loop=1 # åªè¯»ä¸€æ¬¡
    )
    
    total_len = len(dataset)
    print(f"âœ… å‡†å¤‡æ‰«æå…¨éƒ¨ {total_len} ä¸ªæ ·æœ¬...")
    print(">>> è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")

    # å•è¿›ç¨‹æ‰«æï¼ˆä¸ºäº†é¿å…åºåˆ—åŒ–é—®é¢˜ï¼Œç®€å•ç›´æ¥ï¼‰
    error_count = 0
    for i in tqdm(range(total_len)):
        try:
            # åªè¯» segmentï¼Œä¸åŠ è½½ coord ä»¥åŠ å¿«é€Ÿåº¦
            # æ³¨æ„ï¼šPointcept çš„ dataset å¯èƒ½éœ€è¦åŠ è½½æ–‡ä»¶æ‰èƒ½æ‹¿åˆ° segment
            # è¿™é‡Œæˆ‘ä»¬ç›´æ¥è°ƒ dataset[i]
            data = dataset[i]
            segment = data['segment']
            
            if isinstance(segment, torch.Tensor):
                vals = torch.unique(segment).numpy()
            else:
                vals = np.unique(segment)

            # æ ¸å¿ƒåˆ¤æ–­ï¼šæˆ‘ä»¬ç°åœ¨çš„é…ç½®è®¤ä¸ºåˆæ³•èŒƒå›´æ˜¯ [-1, 0, 1, ..., 18]
            # ä»»ä½•å…¶ä»–å€¼éƒ½ä¼šå¯¼è‡´ crash
            invalid_vals = vals[(vals > 18) | (vals < -1)]
            
            if len(invalid_vals) > 0:
                print(f"\nğŸš¨ æŠ“åˆ°äº†ï¼æ ·æœ¬ [{i}] åŒ…å«éæ³•æ ‡ç­¾: {invalid_vals}")
                print(f"   è¯¥æ ·æœ¬å®Œæ•´æ ‡ç­¾: {vals}")
                error_count += 1
                # æŠ“åˆ°ä¸€ä¸ªå°±å¯ä»¥åœäº†ï¼Œæˆ–è€…ç»§ç»­æ‰¾
                if error_count > 5: break
                
        except Exception as e:
            print(f"\nâš ï¸ æ ·æœ¬ [{i}] è¯»å–å¤±è´¥: {e}")

    if error_count == 0:
        print("\nâœ… å…¨é‡æ‰«æå®Œæˆï¼Œæœªå‘ç°éæ³•æ ‡ç­¾ã€‚é—®é¢˜å¯èƒ½åœ¨ AMP (NaN) æˆ–æ˜¾å­˜ã€‚")
    else:
        print(f"\nâŒ æ‰«æå®Œæˆï¼Œå…±å‘ç° {error_count} ä¸ªåæ ·æœ¬ã€‚")

if __name__ == "__main__":
    check_all_data()