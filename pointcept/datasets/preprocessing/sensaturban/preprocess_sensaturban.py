import os
import numpy as np
import open3d as o3d
from pathlib import Path
from tqdm import tqdm
from concurrent.futures import ProcessPoolExecutor
from itertools import repeat
from plyfile import PlyData

# ========================================================
# ç¡¬ç¼–ç å‚æ•°è®¾ç½® (Hardcoded Parameters)
# ========================================================
RAW_DATA_ROOT = Path("../../../../../../data/datasets/OpenDataLab___SensatUrban/raw/SensatUrban/SensatUrban_Dataset/ply")
OUT_DATA_ROOT = Path("../../../../../../data/datasets/OpenDataLab___SensatUrban/data/processed_10d")

GRID_SIZE = 0.1         # ä¸‹é‡‡æ ·æ ¼ç‚¹å¤§å°
NUM_WORKERS = 2         # è¿›ç¨‹å¹¶è¡Œæ•° (å»ºè®®è®¾ä¸º CPU æ ¸å¿ƒæ•°)
KNN_K = 16              # è®¡ç®—å‡ ä½•ç‰¹å¾çš„è¿‘é‚»æ•°
CHUNK_SIZE = (50, 50)   # åˆ‡å—å¤§å° (meters)
CHUNK_STRIDE = (25, 25) # åˆ‡å—æ­¥é•¿ (meters)

# éªŒè¯é›†é€‰å–çš„ Block å
VAL_BLOCKS = ["birmingham_block_1", "birmingham_block_6", "cambridge_block_12", "cambridge_block_6"]

# ========================================================
# æ ¸å¿ƒè®¡ç®—æ¨¡å—
# ========================================================

def extract_geometric_features(points, k=16):
    """ä½¿ç”¨ Open3D é«˜é€Ÿæå–å‡ ä½•ç‰¹å¾å€¼"""
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(points)
    pcd_tree = o3d.geometry.KDTreeFlann(pcd)
    
    n_points = len(points)
    eigenvalues = np.zeros((n_points, 3), dtype=np.float32)
    
    points_np = np.asarray(pcd.points)
    for i in range(n_points):
        # 1. KNN æœç´¢
        [_, idx, _] = pcd_tree.search_knn_vector_3d(points_np[i], k)
        neighbors = points_np[idx]
        
        if len(neighbors) >= 3:
            # 2. è®¡ç®—å±€éƒ¨åæ–¹å·®å¹¶æ±‚ç‰¹å¾å€¼
            cov = np.cov(neighbors.T)
            vals, _ = np.linalg.eigh(cov) # é»˜è®¤ä»Žå°åˆ°å¤§: lambda_1, lambda_2, lambda_3
            
            # 3. å½’ä¸€åŒ– (è®©ç‰¹å¾å€¼è¡¨ç¤ºæ¦‚çŽ‡ï¼šçº¿æ€§ã€å¹³é¢ã€æ•£å°„)
            sum_vals = np.sum(vals) + 1e-6
            eigenvalues[i] = vals / sum_vals # ç»“æžœåœ¨ [0, 1] ä¹‹é—´
            
    return eigenvalues

def process_scene(scene_path):
    scene_path = Path(scene_path)
    scene_name = scene_path.stem.lower()
    
    # åˆ¤æ–­å½’å±žï¼štrain / val / test
    parent_folder = scene_path.parent.name # 'train' æˆ– 'test'
    if parent_folder == "train":
        save_dir = OUT_DATA_ROOT / ("val" if any(bn in scene_name for bn in VAL_BLOCKS) else "train")
    else:
        save_dir = OUT_DATA_ROOT / "test"

    # 1. è¯»å– PLY æ•°æ®
    try:
        with open(str(scene_path), 'rb') as f:
            plydata = PlyData.read(f)
        vertex = plydata['vertex']
        points = np.stack([vertex['x'], vertex['y'], vertex['z']], axis=1).astype(np.float32)
        colors = np.stack([vertex['red'], vertex['green'], vertex['blue']], axis=1).astype(np.uint8) if 'red' in vertex else np.zeros_like(points, dtype=np.uint8)
        labels = np.array(vertex['class' if 'class' in vertex else 'label']).astype(np.int16) if ('class' in vertex or 'label' in vertex) else np.full(points.shape[0], 255, dtype=np.int16)
    except Exception as e:
        return f"âŒ Error {scene_name}: {e}"

    # 2. åæ ‡å¹³ç§» & Grid Sampling
    points -= points.min(axis=0)
    
    # æå– Grid Density (ç‰¹å¾ç¬¬ 10 ç»´)
    scaled_coord = points / GRID_SIZE
    grid_coord = np.floor(scaled_coord).astype(int)
    _, indices, counts = np.unique(grid_coord, axis=0, return_index=True, return_counts=True)
    
    points = points[indices]
    colors = colors[indices]
    labels = labels[indices]
    grid_density = counts.astype(np.float32).reshape(-1, 1) # å±€éƒ¨å¯†åº¦è®¡æ•°

    # 3. è®¡ç®— 3 ç»´ç‰¹å¾å€¼ (ç‰¹å¾ç¬¬ 7, 8, 9 ç»´)
    # åœ¨ä¸‹é‡‡æ ·åŽçš„ç‚¹ä¸Šç®—ï¼Œé€Ÿåº¦æžå¿«
    eigen_feats = extract_geometric_features(points, k=KNN_K)
    
    # æ‹¼æŽ¥æˆ 4 ç»´é¢å¤–ç‰¹å¾ (Eigenvalues + Density)
    extra_feat = np.concatenate([eigen_feats, grid_density], axis=1).astype(np.float32)

    # 4. åˆ‡å—ä¿å­˜ (Chunking)
    x_max, y_max = points.max(axis=0)[:2]
    chunk_idx = 0
    
    for x in np.arange(0, x_max, CHUNK_STRIDE[0]):
        for y in np.arange(0, y_max, CHUNK_STRIDE[1]):
            mask = (points[:, 0] >= x) & (points[:, 0] < x + CHUNK_SIZE[0]) & \
                   (points[:, 1] >= y) & (points[:, 1] < y + CHUNK_SIZE[1])
            
            if np.sum(mask) < 1000: continue # è¿‡æ»¤ç‚¹æ•°å¤ªå°‘çš„å—
            
            chunk_path = save_dir / f"{scene_name}_{chunk_idx}"
            chunk_path.mkdir(parents=True, exist_ok=True)
            
            np.save(chunk_path / "coord.npy", points[mask])
            np.save(chunk_path / "color.npy", colors[mask])
            np.save(chunk_path / "segment.npy", labels[mask])
            np.save(chunk_path / "extra_feat.npy", extra_feat[mask]) # å…³é”®ï¼šå­˜å‚¨ 4 ç»´å‡ ä½•å…ˆéªŒ
            
            chunk_idx += 1

    return f"âœ… {scene_name} finished. Chunks: {chunk_idx}"

# ========================================================
# ä¸»ç¨‹åºå…¥å£
# ========================================================
if __name__ == "__main__":
    # æ‰«ææ‰€æœ‰ ply æ–‡ä»¶
    ply_files = sorted(list(RAW_DATA_ROOT.glob("**/*.ply")))
    print(f"ðŸš€ Total scenes: {len(ply_files)} | Workers: {NUM_WORKERS}")
    
    # å¤šè¿›ç¨‹æ‰§è¡Œ
    with ProcessPoolExecutor(max_workers=NUM_WORKERS) as pool:
        results = list(tqdm(pool.map(process_scene, ply_files), total=len(ply_files)))
        
    for res in results:
        print(res)