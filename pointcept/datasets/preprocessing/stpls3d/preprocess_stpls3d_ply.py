"""
STPLS3D Preprocessing Script (Raw PLY to NPY Chunks)
Location: pointcept/datasets/preprocessing/stpls3d/preprocess_stpls3d_ply.py
Author: Bole's Assistant
"""

import os
import argparse
import glob
import numpy as np
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor
from itertools import repeat
from pathlib import Path
from tqdm import tqdm

# ä¾èµ–æ£€æŸ¥
try:
    from plyfile import PlyData
except ImportError:
    raise ImportError("è¯·å…ˆå®‰è£…ä¾èµ–åº“: pip install plyfile")

def process_scene(scene_path, out_root, grid_size=0.1, chunk_size=(50, 50), chunk_stride=(25, 25)):
    """
    æ ¸å¿ƒå¤„ç†å‡½æ•°ï¼šè¯»å–PLY -> ä½“ç´ ä¸‹é‡‡æ · -> æ»‘åŠ¨çª—å£åˆ‡å— -> ä¿å­˜NPY
    """
    scene_path = Path(scene_path)
    # èŽ·å–æ–‡ä»¶åä½œä¸ºåœºæ™¯å (åŽ»é™¤åŽç¼€)
    scene_name = scene_path.stem
    
    # ------------------------------------------------------------------
    # 1. è¯»å– PLY æ–‡ä»¶
    # ------------------------------------------------------------------
    try:
        with open(str(scene_path), 'rb') as f:
            plydata = PlyData.read(f)
        
        vertex = plydata['vertex']
        
        # æå–åæ ‡ (x, y, z)
        points = np.stack([vertex['x'], vertex['y'], vertex['z']], axis=1).astype(np.float32)
        
        # æå–é¢œè‰² (red, green, blue) - å¤„ç†å¯èƒ½ç¼ºå¤±çš„æƒ…å†µ
        if 'red' in vertex and 'green' in vertex and 'blue' in vertex:
            colors = np.stack([vertex['red'], vertex['green'], vertex['blue']], axis=1).astype(np.uint8)
        else:
            # å¦‚æžœæ²¡æœ‰é¢œè‰²ï¼Œå¡«å……å…¨0æˆ–å…¨127
            colors = np.zeros_like(points, dtype=np.uint8)
        
        # æå–æ ‡ç­¾ (class æˆ– label) - å…³é”®æ­¥éª¤ï¼
        if 'class' in vertex:
            labels = np.array(vertex['class']).astype(np.int16)
        elif 'label' in vertex:
            labels = np.array(vertex['label']).astype(np.int16)
        else:
            # å¦‚æžœå®Œå…¨æ²¡æœ‰æ ‡ç­¾ï¼ˆæ¯”å¦‚æµ‹è¯•é›†ï¼‰ï¼Œå¡«å…… 255 (ignore_index)
            # print(f"âš ï¸ Warning: {scene_name} has no label field. Filling with 255.")
            labels = np.full(points.shape[0], 255, dtype=np.int16)
            
    except Exception as e:
        return f"âŒ Error reading {scene_name}: {e}"

    # ------------------------------------------------------------------
    # 2. Grid Sampling (ä½“ç´ ä¸‹é‡‡æ ·)
    # ------------------------------------------------------------------
    # è¿™ä¸€æ­¥å¯¹äºŽ 5090 æ˜¾å­˜è‡³å…³é‡è¦ï¼Œå“ªæ€•æ˜¯ 24GB/32GB æ˜¾å­˜ï¼Œå¦‚æžœä¸ä¸‹é‡‡æ ·ï¼Œå‡ åƒä¸‡ä¸ªç‚¹ä¹Ÿä¼šçˆ†
    if grid_size is not None and grid_size > 0:
        scaled_coord = points / grid_size
        grid_coord = np.floor(scaled_coord).astype(int)
        
        # èŽ·å–ä½“ç´ åŽ»é‡åŽçš„ç´¢å¼•
        _, indices = np.unique(grid_coord, axis=0, return_index=True)
        
        points = points[indices]
        colors = colors[indices]
        labels = labels[indices]

    # ------------------------------------------------------------------
    # 3. Sliding Window Chunking (æ»‘åŠ¨çª—å£åˆ‡å—)
    # ------------------------------------------------------------------
    # å½’ä¸€åŒ–åæ ‡ä»¥ä¾¿è®¡ç®—åˆ‡å—ä½ç½®
    coord_min = points.min(axis=0)
    coord_rel = points - coord_min
    
    x_max, y_max = coord_rel.max(axis=0)[:2]
    
    # å®šä¹‰è¾“å‡ºæ–‡ä»¶å¤¹åç§°è§„èŒƒï¼šgrid0.10_chunk50x50_stride25x25
    folder_name = f"grid{grid_size:.2f}_chunk{chunk_size[0]}x{chunk_size[1]}_stride{chunk_stride[0]}x{chunk_stride[1]}"
    save_dir_root = out_root / folder_name
    
    chunk_idx = 0
    saved_count = 0
    
    # ç”Ÿæˆæ»‘åŠ¨çª—å£åæ ‡
    x_range = np.arange(0, x_max, chunk_stride[0])
    y_range = np.arange(0, y_max, chunk_stride[1])

    for x in x_range:
        for y in y_range:
            # ç­›é€‰å½“å‰çª—å£å†…çš„ç‚¹
            mask = (
                (coord_rel[:, 0] >= x) & (coord_rel[:, 0] < x + chunk_size[0]) &
                (coord_rel[:, 1] >= y) & (coord_rel[:, 1] < y + chunk_size[1])
            )
            
            # è¿‡æ»¤æŽ‰æžå°çš„ç¢Žç‰‡å— (å°‘äºŽ1000ä¸ªç‚¹é€šå¸¸æ— æ³•è®­ç»ƒ)
            if np.sum(mask) < 1000:
                continue
            
            # æå–æ•°æ®
            chunk_points = points[mask]
            chunk_colors = colors[mask]
            chunk_labels = labels[mask]
            
            # ä¿å­˜è·¯å¾„ï¼šSceneName_ChunkID
            chunk_name = f"{scene_name}_{chunk_idx}"
            chunk_save_path = save_dir_root / chunk_name
            chunk_save_path.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜ä¸º Pointcept æ ‡å‡†æ ¼å¼
            np.save(chunk_save_path / "coord.npy", chunk_points)
            np.save(chunk_save_path / "color.npy", chunk_colors)
            np.save(chunk_save_path / "segment.npy", chunk_labels)
            
            chunk_idx += 1
            saved_count += 1

    return f"âœ… {scene_name}: Generated {saved_count} chunks"

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--dataset_root", type=str, required=True, help="Path to raw .ply folder")
    parser.add_argument("--output_root", type=str, required=True, help="Path to save processed .npy")
    parser.add_argument("--grid_size", type=float, default=0.1, help="Voxel size for downsampling")
    parser.add_argument("--chunk_size", type=int, default=50, help="Chunk size in meters")
    parser.add_argument("--chunk_stride", type=int, default=25, help="Stride size in meters")
    parser.add_argument("--num_workers", type=int, default=4, help="Number of parallel workers")
    args = parser.parse_args()

    dataset_path = Path(args.dataset_root)
    output_path = Path(args.output_root)
    
    # æœç´¢ .ply æ–‡ä»¶
    ply_files = sorted(list(dataset_path.glob("*.ply")))
    
    if not ply_files:
        print(f"âŒ Error: No .ply files found in {dataset_path}")
        # å°è¯•é€’å½’æœç´¢
        print("   Trying recursive search...")
        ply_files = sorted(list(dataset_path.glob("**/*.ply")))
        if not ply_files:
            exit(1)

    print(f"ðŸš€ Found {len(ply_files)} PLY files. Starting preprocessing...")
    print(f"âš™ï¸  Config: Grid={args.grid_size}m, Chunk={args.chunk_size}m, Stride={args.chunk_stride}m")

    # å¹¶è¡Œå¤„ç†
    with ProcessPoolExecutor(max_workers=args.num_workers) as pool:
        results = list(tqdm(
            pool.map(
                process_scene,
                ply_files,
                repeat(output_path),
                repeat(args.grid_size),
                repeat((args.chunk_size, args.chunk_size)),
                repeat((args.chunk_stride, args.chunk_stride)),
            ),
            total=len(ply_files),
            desc="Preprocessing"
        ))

    print("\nProcessing Report:")
    for res in results:
        print(res)